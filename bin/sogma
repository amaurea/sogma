#!/usr/bin/env python
import argparse
parser = argparse.ArgumentParser()
parser.add_argument("obsinfo")
parser.add_argument("area")
parser.add_argument("odir")
parser.add_argument("-Q", "--query",   type=str, default=None)
parser.add_argument(      "--wafers",  type=str, default=None)
parser.add_argument(      "--bands",   type=str, default=None)
parser.add_argument("-p", "--prefix",  type=str, default=None)
parser.add_argument("-v", "--verbose", action="count", default=1)
parser.add_argument("-q", "--quiet",   action="count", default=0)
parser.add_argument("-n", "--maxfiles",type=int, default=None)
parser.add_argument("-i", "--startfile",type=int, default=None)
args = parser.parse_args()

# Should some of this be factored out into an
# SO-specific mapmaker class?

import numpy as np, os, time, sys
from pixell import enmap, utils, mpi, colors
import cupy
import gpu_mm
from sogma import gutils, logging, gmem, mapmaking, files, tiling, nmat
from sogma.gmem import scratch

comm   = mpi.COMM_WORLD
dtype_tod  = np.float32
dtype_map  = np.float32
shape, wcs = enmap.read_map_geometry(args.area)
L = logging.Logger(id=comm.rank, level=args.verbose-args.quiet).setdefault()
L.print("Init", level=0, id=0, color=colors.lgreen)
# Set up our gpu scratch memory. These will be used for intermediate calculations.
# Comments give estimated memory requirements. May not need to declear all these
# here any more. Only the ones that will be shared across multiple objects need to be
scratch.tod      = gmem.CuBuffer("tod")       # 1 GB
scratch.ft       = gmem.CuBuffer("ft")        # 1 GB
scratch.pointing = gmem.CuBuffer("pointing")  # 3 GB
scratch.plan     = gmem.CuBuffer("plan")      # 0.1  GB
scratch.nmat_work= gmem.CuBuffer("nmat_work") # 0.15 GB
scratch.cut      = gmem.CuBuffer("cut")       # 0.3  GB (up to 30% cut)
# Disable the cufft cache. It uses too much gpu memory
cupy.fft.config.get_plan_cache().set_memsize(0)
# Set up our data loader
loader  = files.Loader(args.obsinfo)
obsinfo = loader.query(args.query, wafers=args.wafers, bands=args.bands)[args.startfile:][:args.maxfiles]
nfile   = len(obsinfo)
L.print("Mapping %d tods with %d mpi tasks" % (nfile, comm.size), level=0, id=0, color=colors.lgreen)
prefix = args.odir + "/"
if args.prefix: prefix += args.prefix + "_"
utils.mkdir(args.odir)
# Set up the signals we will solve for
signal_map = mapmaking.SignalMapGpu(shape, wcs, comm, dtype=np.float32)
# FIXME: poly cuts need a better preconditioner or better basis.
# The problem is probably that the legendre polynomials lose their orthogonality
# with the truncated block approach used here
#signal_cut = mapmaking.SignalCutPolyGpu(comm, precon="var")
signal_cut = mapmaking.SignalCutFullGpu(comm)
# Set up the mapmaker
mapmaker = mapmaking.MLMapmaker(signals=[signal_cut,signal_map], dtype=dtype_tod, verbose=True, noise_model=nmat.NmatDetvecsGpu())
# Add our observations
for ind in range(comm.rank, nfile, comm.size):
	id    = obsinfo.id[ind]
	t1    = time.time()
	try:
		data  = loader.load(id)
	except utils.DataMissing as e:
		L.print("Skipped %s: %s" % (id, str(e)), level=2, color=colors.red)
		continue
	t2    = time.time()
	mapmaker.add_obs(id, data, deslope=False)
	gmem.gpu_garbage_collect()
	del data
	t3    = time.time()
	L.print("Processed %s in %6.3f. Read %6.3f Add %6.3f" % (id, t3-t1, t2-t1, t3-t2), level=2)

nobs = comm.allreduce(len(mapmaker.data))
if nobs == 0:
	L.print("No tods survived!", id=0, level=0, color=colors.red)
	mpi.Finalize()
	sys.exit(1)

# Solve the equation system
for step in mapmaker.solve():
	L.print("CG %4d %15.7e (%6.3f s)" % (step.i, step.err, step.t), id=0, level=1, color=colors.lgreen)
	if step.i % 10 == 0:
		for signal, val in zip(mapmaker.signals, step.x):
			if signal.output:
				signal.write(prefix, "map%04d" % step.i, val)
